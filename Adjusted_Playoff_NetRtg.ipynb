{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "nba_possession_data_seasons = np.arange(1974, 2025, 1)\n",
        "play_by_play_data_seasons = np.arange(1997, 2025, 1)\n",
        "nba_pre_possession_data_seasons = np.arange(1952, 1974, 1)\n",
        "aba_possession_data_seasons = np.arange(1974, 1977, 1)\n",
        "aba_pre_possession_data_seasons = np.arange(1968, 1974, 1)\n",
        "\n",
        "all_nba_seasons = np.arange(1952, 2025, 1)\n",
        "all_aba_seasons = np.arange(1968, 1977, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes\n",
        "\n",
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.12, point['y']+.25, str(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))\n",
        "\n",
        "def label_point_year(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.12, point['y'], int(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))\n",
        "\n",
        "plot_colors_set_list = [\"#FF0000\", \"#D3A6D6\", \"#916613\", \"#00A4A0\", \"#FF7F00\", \"#ABFFD2\", \"#610077\", \"#173E4C\", \"#00A54C\", \"#FF00A1\", \"#FFFE00\", \"#0B1ADD\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cn6OcXIY66Fb"
      },
      "outputs": [],
      "source": [
        "#@title Import Selenium\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jozq2eJRHQHc"
      },
      "outputs": [],
      "source": [
        "#@title Start Webdriver and VirtualDisplay\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "service = Service(executable_path=r'/usr/bin/chromedriver')\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "#options = Options()\n",
        "#options.add_argument(\"--headless\")\n",
        "#options.add_argument(\"--no-sandbox\")\n",
        "#options.headless = True\n",
        "\n",
        "#wd = webdriver.Chrome(\"/usr/bin/chromedriver\", options=options)\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Scrape Playoff Teams' OffRtg+ and rDefRtg+\n",
        "def scrape_playoff_rOffRtg_rDefRtg(origal_team_df):\n",
        "\n",
        "\n",
        "  teams_defense = pd.read_csv('/content/nba_Team_DefRtg_Allowed_74-24_df.csv', index_col=False, encoding='utf8')\n",
        "  teams_offense = pd.read_csv('/content/nba_Team_OffRtg_74-24_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  fiftytwo_seventythree_off_def_rtgs = pd.read_csv('/content/nba_Team_Estimated_Pace_52-73_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  missing_pistons_lakers_60_62 = pd.read_csv('/content/missing_fga_60_62.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "  team_df = pd.DataFrame(columns = ['Year', 'Team', 'OffRtg+', 'DefRtg+', 'NetRtg+', 'MP'])\n",
        "  total_series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'NetRtg+', 'MP'])\n",
        "\n",
        "  for idx, row in origal_team_df.iterrows():\n",
        "\n",
        "    use_different_pace_formula = 0\n",
        "    dont_estimate_pace = 0\n",
        "\n",
        "    original_team = str(row['Team'])\n",
        "    series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "\n",
        "    team_url = \"https://www.basketball-reference.com/teams/\" + row['Team'] + \"/\" + str(row['Year']) + \".html\"\n",
        "\n",
        "    html = urlopen(team_url)\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'info'}):\n",
        "      second_div = first_div.find('div', attrs={'id': 'meta'})\n",
        "      second_div = str(second_div)\n",
        "      ref_urls = re.findall(r'/\\w+\\/\\d+[0-9abcdefghijklmnopqrstuvwxyz-]+', second_div)\n",
        "      urls = []\n",
        "      for ref_url in ref_urls:\n",
        "        if \"eastern\" in ref_url or \"western\" in ref_url or \"finals\" in ref_url:\n",
        "          ref_url = \"https://www.basketball-reference.com\" + ref_url + \".html\"\n",
        "          urls.append(ref_url)\n",
        "    for series_url in urls:\n",
        "\n",
        "      time.sleep(6)\n",
        "      html = urlopen(series_url)\n",
        "      soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_four_factors'})\n",
        "\n",
        "      second_div = str(second_div)\n",
        "\n",
        "      teams = re.findall(r'/\\w+\\/\\d+', second_div)\n",
        "      count = 0\n",
        "      for team in teams:\n",
        "        if count == 0:\n",
        "          if str(row['Team']) in team:\n",
        "            team_in = 0\n",
        "          else:\n",
        "            team_in = 1\n",
        "            other_team = team\n",
        "        else:\n",
        "          if str(row['Team']) not in team:\n",
        "            other_team = team\n",
        "        count = count + 1\n",
        "      year = row['Year']\n",
        "      other_team = other_team.replace(f'{year}', '')\n",
        "      other_team = other_team.replace(f'/', '')\n",
        "\n",
        "      rtgs_untrimmed = re.findall(r'off_rtg\" >\\d+.\\d+', second_div)\n",
        "\n",
        "      # no OffRtg's. Need to estimate them given boxscore.\n",
        "      if not rtgs_untrimmed:\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "\n",
        "        # most likely have TOV data\n",
        "        if year >= 1974:\n",
        "\n",
        "          # team data to estimate pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            mp_untrimmed = mp_untrimmed[-1]\n",
        "            mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            tov_untrimmed = tov_untrimmed[-1]\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "\n",
        "            fga = int(series_data['FGA'])\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            OffRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            original_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "          else:\n",
        "            original_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          use_different_pace_formula = 0\n",
        "          dont_estimate_pace = 0\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            tov_untrimmed = tov_untrimmed[-1]\n",
        "            tov = tov_untrimmed.replace(f'data-stat=\"tov\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                  TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            fga = int(series_data['FGA'])\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            DefRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "          else:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "\n",
        "          other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "          other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_offrtg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "        # will not have TOV data\n",
        "        else:\n",
        "          if year >= 1971:\n",
        "            TOV_percent = 0.158\n",
        "          else:\n",
        "            TOV_percent = 0.161\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            mp_untrimmed = mp_untrimmed[-1]\n",
        "            mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              fga = missing_pistons_lakers_60_62[(missing_pistons_lakers_60_62['Team'] == original_team) & (missing_pistons_lakers_60_62['Year'] == year)]\n",
        "              fga = fga['FGA']\n",
        "              fga = int(fga)\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              fga = missing_pistons_lakers_60_62[(missing_pistons_lakers_60_62['Team'] == original_team) & (missing_pistons_lakers_60_62['Year'] == year)]\n",
        "              fga = fga['FGA']\n",
        "              fga = int(fga)\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          possessions = (total_fga + (0.4 * total_fta) - ORB_percent * (total_fga - total_fg) + (-TOV_percent * (total_fga + 0.44 * total_fta) / (TOV_percent - 1))) / 2\n",
        "          DefRtg = pts / possessions * 100\n",
        "          OffRtg = original_pts / possessions * 100\n",
        "\n",
        "          other_team_defrtg_ortg = fiftytwo_seventythree_off_def_rtgs[(fiftytwo_seventythree_off_def_rtgs['Year'] == year) & (fiftytwo_seventythree_off_def_rtgs['Team'] == other_team)]\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg_ortg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_defrtg_ortg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "      # have OffRtg's, can use them\n",
        "      else:\n",
        "        count = 0\n",
        "        for rtg in rtgs_untrimmed:\n",
        "          rtg = rtg.replace('off_rtg\" >', '')\n",
        "          if count == 0 and team_in == 0:\n",
        "            off_rtg = rtg\n",
        "          elif count == 1 and team_in == 0:\n",
        "            def_rtg = rtg\n",
        "          elif count == 0 and team_in == 1:\n",
        "            def_rtg = rtg\n",
        "          elif count == 1 and team_in == 1:\n",
        "            off_rtg = rtg\n",
        "          count = count + 1\n",
        "\n",
        "        other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "\n",
        "        other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "        r_OffRtg = float(off_rtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "        r_DefRtg = float(other_team_offrtg['OffRtg']) / float(def_rtg)* 100\n",
        "\n",
        "        r_OffRtg = round(r_OffRtg, 1)\n",
        "        r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "\n",
        "        first_div = soup.find('div', attrs={'id': 'content'})\n",
        "        second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "        first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "        if first_table == None:\n",
        "          second_div_str = str(second_div)\n",
        "          mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "          mp_untrimmed = mp_untrimmed[-1]\n",
        "          mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "          mp = int(mp) // 5\n",
        "        else:\n",
        "          header = first_table.find('thead')\n",
        "          foot = first_table.find('tfoot')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "          rows = foot.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "          #create df\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          pts_count = 0\n",
        "          mp_count = 0\n",
        "          cols = []\n",
        "          for column in series_data.columns:\n",
        "            if column == 'MP':\n",
        "              if mp_count == 1:\n",
        "                cols.append(f'MPG')\n",
        "              else:\n",
        "                cols.append(f'MP')\n",
        "              mp_count+=1\n",
        "              continue\n",
        "            if column == 'PTS':\n",
        "              if pts_count == 1:\n",
        "                cols.append(f'PTS/G')\n",
        "              else:\n",
        "                cols.append(f'PTS')\n",
        "              pts_count+=1\n",
        "              continue\n",
        "            cols.append(column)\n",
        "          series_data.columns = cols\n",
        "\n",
        "          mp = int(series_data['MP'])\n",
        "          mp = int(mp // 5)\n",
        "\n",
        "      new_row = pd.DataFrame(np.array([[year, original_team, other_team, r_OffRtg, r_DefRtg, (r_OffRtg + r_DefRtg - 100), mp]]), columns=['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'NetRtg+', 'MP'])\n",
        "      series_df = pd.concat([series_df, new_row], ignore_index=True)\n",
        "      total_series_df = pd.concat([total_series_df, new_row], ignore_index=True)\n",
        "      series_df['MP'] = series_df['MP'].astype(int)\n",
        "      total_series_df['MP'] = total_series_df['MP'].astype(int)\n",
        "\n",
        "    mp = int(series_df['MP'].sum())\n",
        "    print(series_df)\n",
        "\n",
        "    for idx, row in series_df.iterrows():\n",
        "\n",
        "      series_df.loc[idx, 'OffRtg+_Portion'] = float(series_df.loc[idx, 'OffRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "      series_df.loc[idx, 'DefRtg+_Portion'] = float(series_df.loc[idx, 'DefRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "    rOffRtg_avg = series_df[f'OffRtg+_Portion'].sum().round(1)\n",
        "    rDefRtg_avg = series_df[f'DefRtg+_Portion'].sum().round(1)\n",
        "\n",
        "    new_row = pd.DataFrame(np.array([[year, original_team, rOffRtg_avg, rDefRtg_avg,(rOffRtg_avg + rDefRtg_avg - 100), mp]]), columns=['Year', 'Team', 'OffRtg+', 'DefRtg+', 'NetRtg+', 'MP'])\n",
        "    team_df = pd.concat([team_df, new_row], ignore_index=True)\n",
        "\n",
        "    total_series_df.to_csv('nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index=False)\n",
        "    team_df.to_csv('nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index=False)\n",
        "    print(team_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xrnh4EJm1fyJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teams = pd.read_csv('', index_col=False, encoding='utf8')\n",
        "scrape_playoff_rOffRtg_rDefRtg(teams)"
      ],
      "metadata": {
        "id": "ZTFTBTFwYI_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "finished = []\n",
        "count = 0\n",
        "for idx, row in teams.iterrows():\n",
        "  if row['Team'] not in finished:\n",
        "    print(row['Team'])\n",
        "    specific_team = teams[(teams['Team'] == row['Team'])]\n",
        "    specific_team.to_csv(f\"{row['Team']}_Adjusted_Playoff_NetRtg_Series_By_Series.csv\", index=False)\n",
        "    finished.append(row['Team'])"
      ],
      "metadata": {
        "id": "l31nUBczL0LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Total Franchise Index\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "team_list = []\n",
        "final_team_df = pd.DataFrame(columns = ['Team', 'OffRtg+', 'DefRtg+', 'NetRtg+', 'MP'])\n",
        "\n",
        "for team in teams['Team']:\n",
        "  if team not in team_list:\n",
        "    team_list.append(team)\n",
        "\n",
        "for team in team_list:\n",
        "  one_team = teams[(teams['Team'] == team)]\n",
        "  years = len(one_team)\n",
        "\n",
        "  stat = 'OffRtg+'\n",
        "  stat_2 = 'DefRtg+'\n",
        "  stat_3 = 'NetRtg+'\n",
        "  x_yearpeak_team_name(one_team, stat, stat_2, stat_3, years)\n",
        "  import_team_data = pd.read_csv(f\"{team}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "\n",
        "  final_team_df = pd.concat([final_team_df, import_team_data], ignore_index=False)\n",
        "final_team_df = final_team_df.sort_values('Team',ascending=True)\n",
        "final_team_df.to_csv(f\"Franchise_Index.csv\", index=False)\n",
        "print(final_team_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yCWAmIrjZnBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Determine Opponents' NetRtg+\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "specific_team = \"BOS\"\n",
        "min_year = 1980\n",
        "max_year = 1991\n",
        "\n",
        "specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] >= min_year)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] <= max_year)]\n",
        "\n",
        "total_defrtg = 0\n",
        "stat = 'NetRtg+'\n",
        "\n",
        "total_opponents_df = pd.DataFrame(columns=[f'{stat}', 'MP'])\n",
        "\n",
        "team_finished = []\n",
        "\n",
        "for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "  opp = row['Opp']\n",
        "  year = row['Year']\n",
        "  opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "  opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "  if not opp_playoffs.empty:\n",
        "    team_was = str(row['Opp']) + str(row['Year'])\n",
        "    if team_was not in team_finished:\n",
        "      mp = int(opp_playoffs['MP'].sum())\n",
        "      opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "      rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, mp]\n",
        "      print(opp_playoffs)\n",
        "      tmp_sum = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      team_finished.append(team_was)\n",
        "\n",
        "\n",
        "mp = int(total_opponents_df['MP'].sum())\n",
        "total_opponents_df['Portion'] = total_opponents_df[f'{stat}'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "rtg = total_opponents_df[f'Portion'].sum().round(1)\n",
        "print(\"\\n\", rtg)\n",
        "print(mp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d6sY9irYMF5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team = \"NYK\"\n",
        "first_year = 2000\n",
        "last_year = 2001"
      ],
      "metadata": {
        "id": "Smp41yFvZ-no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years_list = [1971, 1975, 1978]"
      ],
      "metadata": {
        "id": "x_wmvILXSOyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Determine Opponents' OffRtg+\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "specific_team = team\n",
        "\n",
        "specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] >= first_year)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] <= last_year)]\n",
        "\n",
        "total_defrtg = 0\n",
        "stat = 'OffRtg+'\n",
        "\n",
        "total_opponents_df = pd.DataFrame(columns=[f'{stat}', 'MP'])\n",
        "\n",
        "team_finished = []\n",
        "\n",
        "for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "  opp = row['Opp']\n",
        "  year = row['Year']\n",
        "  opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "  opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "  if not opp_playoffs.empty:\n",
        "    team_was = str(row['Opp']) + str(row['Year'])\n",
        "    if team_was not in team_finished:\n",
        "      mp = int(opp_playoffs['MP'].sum())\n",
        "      opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "      rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, mp]\n",
        "      #print(opp_playoffs)\n",
        "      tmp_sum = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      team_finished.append(team_was)\n",
        "      #print(tmp_sum)\n",
        "\n",
        "\n",
        "mp = int(total_opponents_df['MP'].sum())\n",
        "total_opponents_df['Portion'] = total_opponents_df[f'{stat}'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "rtg = total_opponents_df[f'Portion'].sum().round(1)\n",
        "print(rtg)\n",
        "print(mp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LLu6ci71Z9Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba370fcb-da9a-4717-d23d-dcedf3a4c8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110.5\n",
            "2650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Determine Opponents' DefRtg+\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "specific_team = team\n",
        "\n",
        "specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] >= first_year)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] <= last_year)]\n",
        "total_defrtg = 0\n",
        "stat = 'DefRtg+'\n",
        "\n",
        "total_opponents_df = pd.DataFrame(columns=[f'{stat}', 'MP'])\n",
        "\n",
        "team_finished = []\n",
        "\n",
        "for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "  opp = row['Opp']\n",
        "  year = row['Year']\n",
        "  opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "  opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "  if not opp_playoffs.empty:\n",
        "    team_was = str(row['Opp']) + str(row['Year'])\n",
        "    if team_was not in team_finished:\n",
        "      mp = int(opp_playoffs['MP'].sum())\n",
        "      opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "      rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, mp]\n",
        "      #print(opp_playoffs)\n",
        "      team_finished.append(team_was)\n",
        "\n",
        "\n",
        "mp = int(total_opponents_df['MP'].sum())\n",
        "total_opponents_df['Portion'] = total_opponents_df[f'{stat}'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "rtg = total_opponents_df[f'Portion'].sum().round(1)\n",
        "print(rtg)\n",
        "print(mp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kg9mujcM52-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22139b55-f8d5-42ad-c62c-f063892950bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104.3\n",
            "4782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print OffRtg or DefRtg over a stretch for a team (non-consecutive)\n",
        "def print_rtg_over_stretch(stat, team, first_year, second_year):\n",
        "  teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  if stat == \"d\":\n",
        "    stat = \"DefRtg+\"\n",
        "  elif stat == \"o\":\n",
        "    stat = \"OffRtg+\"\n",
        "  elif stat == \"n\":\n",
        "    stat = \"NetRtg+\"\n",
        "  specific_team = teams[(teams['Year'].isin(years_list))]\n",
        "  specific_team = specific_team[(specific_team['Team'] == team)]\n",
        "  mp = specific_team['MP'].sum()\n",
        "  print(\"MP: \", mp)\n",
        "\n",
        "  specific_team[f'{stat}_Portion'] = specific_team[f'{stat}'] * (specific_team['MP'] / mp)\n",
        "  peak = specific_team[f'{stat}_Portion'].sum().round(1)\n",
        "\n",
        "  print(f\"{stat}: \", peak)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hYEn4GaAR-9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print OffRtg or DefRtg over a stretch for a team\n",
        "def print_rtg_over_stretch(stat, team, first_year, second_year):\n",
        "  teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  if stat == \"d\":\n",
        "    stat = \"DefRtg+\"\n",
        "  elif stat == \"o\":\n",
        "    stat = \"OffRtg+\"\n",
        "  elif stat == \"n\":\n",
        "    stat = \"NetRtg+\"\n",
        "  specific_team = teams[(teams['Year'] >= first_year)]\n",
        "  specific_team = specific_team[(specific_team['Year'] <= second_year)]\n",
        "  specific_team = specific_team[(specific_team['Team'] == team)]\n",
        "  mp = specific_team['MP'].sum()\n",
        "  print(\"MP: \", mp)\n",
        "\n",
        "  specific_team[f'{stat}_Portion'] = specific_team[f'{stat}'] * (specific_team['MP'] / mp)\n",
        "  peak = specific_team[f'{stat}_Portion'].sum().round(1)\n",
        "\n",
        "  print(f\"{stat}: \", peak)"
      ],
      "metadata": {
        "id": "ltZkHsrL6Yx1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_rtg_over_stretch(\"o\", team, first_year, last_year)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvN-w__ZKkjL",
        "outputId": "7a9e51cd-0e91-4076-bfce-f9887b45123c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP:  1013\n",
            "OffRtg+:  98.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Total Franchise Opponent Stats\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "team_list = []\n",
        "final_team_df = pd.DataFrame(columns = ['Team', 'Opponents OffRtg+', 'Opponents DefRtg+', 'MP'])\n",
        "\n",
        "for team in teams['Team']:\n",
        "  if team not in team_list:\n",
        "    team_list.append(team)\n",
        "\n",
        "for specific_team in team_list:\n",
        "\n",
        "  specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "\n",
        "  total_defrtg = 0\n",
        "  stat = 'OffRtg+'\n",
        "  stat_2 = 'DefRtg+'\n",
        "\n",
        "  total_opponents_df = pd.DataFrame(columns=[f'{stat}', f'{stat_2}', 'MP'])\n",
        "\n",
        "  team_finished = []\n",
        "\n",
        "  for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "    opp = row['Opp']\n",
        "    year = row['Year']\n",
        "    opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "    opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "    if not opp_playoffs.empty:\n",
        "      team_was = str(row['Opp']) + str(row['Year'])\n",
        "      if team_was not in team_finished:\n",
        "        mp = int(opp_playoffs['MP'].sum())\n",
        "        opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "        opp_playoffs[f'{stat_2}_Portion'] = opp_playoffs[f'{stat_2}'] * (opp_playoffs['MP'] / mp)\n",
        "        rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "        rtg_2 = opp_playoffs[f'{stat_2}_Portion'].sum().round(1)\n",
        "        total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, rtg_2, mp]\n",
        "        #print(opp_playoffs)\n",
        "        team_finished.append(team_was)\n",
        "\n",
        "\n",
        "  mp = int(total_opponents_df['MP'].sum())\n",
        "\n",
        "  total_opponents_df['Portion_Off'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "  rtg = total_opponents_df[f'Portion_Off'].sum().round(1)\n",
        "\n",
        "  total_opponents_df['Portion_Def'] = total_opponents_df[f'{stat_2}'] * (total_opponents_df['MP'] / mp)\n",
        "  rtg_2 = total_opponents_df[f'Portion_Def'].sum().round(1)\n",
        "\n",
        "  cols = ['Team', 'Opponents OffRtg+', 'Opponents DefRtg+', 'MP']\n",
        "  df_temp = pd.DataFrame([[specific_team, rtg, rtg_2, mp]], columns=cols)\n",
        "  final_team_df = pd.concat([final_team_df, df_temp], ignore_index=False)\n",
        "\n",
        "outfile = f\"Franchises_Opponent_Stats.csv\"\n",
        "final_team_df = final_team_df.sort_values('Team',ascending=True)\n",
        "final_team_df.to_csv(outfile, index=False)\n",
        "print(final_team_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "51kuILwpeSAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Combine Franchise Index DF's\n",
        "\n",
        "index = pd.read_csv('/content/Franchise_Index.csv', index_col=False, encoding='utf8')\n",
        "opponents = pd.read_csv('/content/Franchises_Opponent_Stats.csv', index_col=False, encoding='utf8')\n",
        "index = index.drop(columns=['DefRtg+', 'NetRtg+'])\n",
        "index['Opponents DefRtg+'] = 0\n",
        "print(index)\n",
        "for idx, team in index.iterrows():\n",
        "  opponent_data = opponents[(opponents['Team'] == team['Team'])]\n",
        "  index.loc[idx, 'Opponents DefRtg+'] = float(opponent_data['Opponents DefRtg+'])\n",
        "print(index)\n",
        "index.to_csv('Combined_Franchise_Index.csv', index=False)"
      ],
      "metadata": {
        "id": "41-Ha7Z1m-n6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentiles"
      ],
      "metadata": {
        "id": "d8T__jfLwQru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "team_data = pd.read_csv('/content/5_year_peak_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "team_data = team_data.sort_values(\"OffRtg+\", ascending=False)\n",
        "team_data = team_data[(team_data['OffRtg+'] >= 108)]\n",
        "print(team_data)"
      ],
      "metadata": {
        "id": "sxhiLCgMmuGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1000-9000 MP Percentiles\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 1000]\n",
        "team_data = team_data[team_data['MP'] <= 1999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'OffRtg+'], ascending=[True, True])\n",
        "team_data = team_data.drop_duplicates('Team', keep='first')\n",
        "\n",
        "team_data.to_csv('1000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 2000]\n",
        "team_data = team_data[team_data['MP'] <= 2999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'OffRtg+'], ascending=[True, True])\n",
        "team_data = team_data.drop_duplicates('Team', keep='first')\n",
        "\n",
        "team_data.to_csv('2000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 3000]\n",
        "team_data = team_data[team_data['MP'] <= 3999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "defense_percentile = stats.percentileofscore(team_data['OffRtg+'], 101)\n",
        "print(defense_percentile)\n",
        "\n",
        "\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'OffRtg+'], ascending=[True, True])\n",
        "team_data = team_data.drop_duplicates('Team', keep='first')\n",
        "\n",
        "team_data.to_csv('3000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 4000]\n",
        "team_data = team_data[team_data['MP'] <= 4999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'OffRtg+'], ascending=[True, True])\n",
        "team_data = team_data.drop_duplicates('Team', keep='first')\n",
        "\n",
        "team_data.to_csv('4000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 5000]\n",
        "team_data = team_data[team_data['MP'] <= 5999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'DefRtg+'], ascending=[True, False])\n",
        "\n",
        "print(team_data)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 6000]\n",
        "team_data = team_data[team_data['MP'] <= 6999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values('DefRtg+', ascending= False)\n",
        "team_data.to_csv('6000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 7000]\n",
        "team_data = team_data[team_data['MP'] <= 7999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'DefRtg+'], ascending=[True, False])\n",
        "team_data = team_data.drop_duplicates('Team', keep='first')\n",
        "team_data.to_csv('7000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 8000]\n",
        "team_data = team_data[team_data['MP'] <= 8999]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'Years'], ascending=[True, True])\n",
        "team_data.to_csv('8000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data = team_data[team_data['MP'] >= 9000]\n",
        "\n",
        "for idx, row in team_data.iterrows():\n",
        "\n",
        "  offense = row['OffRtg+']\n",
        "  defense = row['DefRtg+']\n",
        "  offense_percentile = stats.percentileofscore(team_data['OffRtg+'], offense)\n",
        "  defense_percentile = stats.percentileofscore(team_data['DefRtg+'], defense)\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  team_data.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  team_data.at[idx, 'Def Percentile'] = defense_percentile\n",
        "\n",
        "team_data = team_data[['Team', 'Years', 'OffRtg+',  'Off Percentile','DefRtg+','Def Percentile',  'NetRtg+',  'MP']]\n",
        "team_data = team_data.sort_values(['Team', 'DefRtg+'], ascending=[True, True])\n",
        "team_data.to_csv('9000_MP_Team_Peaks.csv',index=False)\n"
      ],
      "metadata": {
        "id": "_JDbYkO8wRzG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create Percentiles\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "for idx, row in teams.iterrows():\n",
        "\n",
        "  offense_percentile = stats.percentileofscore(teams['OffRtg+'], row['OffRtg+'])\n",
        "  defense_percentile = stats.percentileofscore(teams['DefRtg+'], row['DefRtg+'])\n",
        "  net_percentile = stats.percentileofscore(teams['NetRtg+'], row['NetRtg+'])\n",
        "  offense_percentile = offense_percentile.round(1)\n",
        "  defense_percentile = defense_percentile.round(1)\n",
        "  net_percentile = net_percentile.round(1)\n",
        "  teams.at[idx, 'Off Percentile'] = offense_percentile\n",
        "  teams.at[idx, 'Def Percentile'] = defense_percentile\n",
        "  teams.at[idx, 'Net Percentile'] = net_percentile\n",
        "\n",
        "\n",
        "teams = teams[['Year', 'Team', 'OffRtg+',  'Off Percentile', 'DefRtg+', 'Def Percentile',  'NetRtg+', 'Net Percentile',  'MP']]\n",
        "print(teams)\n",
        "teams.to_csv('nba_Playoff_rOffRtg_rDefRtg_1957_2024_df_percentiles.csv',index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2hpHVD1ouSku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEAM PEAK FUNCTIONS**"
      ],
      "metadata": {
        "id": "A2EJRvOmuS3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title X Year Peaks Functions (Team)\n",
        "\n",
        "# returns if all values in a column are unique.\n",
        "\n",
        "\n",
        "# def x_yearpeak(source_df, valuestring, number_of_seasons_peak):\n",
        "# returns a dataframe containing x year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts x year stretches of 'valuestring' AND the listed years from each x year stretch + minutes played across the 2 seasons.\n",
        "def x_yearpeak(source_df, valuestring, valuestring_2, valuestring_3, number_of_seasons_peak):\n",
        "  x_year_peak = pd.DataFrame(columns = ['Years', 'Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP'])\n",
        "\n",
        "  team_finished = []\n",
        "\n",
        "  for idx, team in source_df.iterrows():\n",
        "\n",
        "    # if player has not already been through function call\n",
        "    if team['Team'] not in team_finished:\n",
        "      single_team_df = source_df[(source_df['Team'] == team['Team'])]\n",
        "      single_team_df = single_team_df.reset_index(drop=True)\n",
        "      number_of_total_team_seasons = len(single_team_df.index)\n",
        "\n",
        "      for season_index in range(0, number_of_total_team_seasons - (number_of_seasons_peak - 1)):\n",
        "\n",
        "        years = ''\n",
        "        non_consecutive_years = 0\n",
        "        end_of_stretch = 0\n",
        "\n",
        "        stretch_of_peak_seasons = single_team_df.iloc[season_index: season_index+number_of_seasons_peak].copy()\n",
        "        stretch_of_peak_seasons = stretch_of_peak_seasons.reset_index(drop=True)\n",
        "        mp = int(stretch_of_peak_seasons['MP'].sum())\n",
        "        stretch_of_peak_seasons[f'{valuestring}_Portion'] = stretch_of_peak_seasons[f'{valuestring}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        stretch_of_peak_seasons[f'{valuestring_2}_Portion'] = stretch_of_peak_seasons[f'{valuestring_2}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        stretch_of_peak_seasons[f'{valuestring_3}_Portion'] = stretch_of_peak_seasons[f'{valuestring_3}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        valuestring_peak = stretch_of_peak_seasons[f'{valuestring}_Portion'].sum().round(2)\n",
        "        valuestring_peak_2 = stretch_of_peak_seasons[f'{valuestring_2}_Portion'].sum().round(2)\n",
        "        valuestring_peak_3 = stretch_of_peak_seasons[f'{valuestring_3}_Portion'].sum().round(2)\n",
        "\n",
        "        prev_year = stretch_of_peak_seasons.iloc[0]['Year']\n",
        "        for year in stretch_of_peak_seasons['Year']:\n",
        "          if year - prev_year > 3:\n",
        "            end_of_stretch = 1\n",
        "          prev_year = year\n",
        "        if end_of_stretch == 1:\n",
        "          continue\n",
        "        prev_year = stretch_of_peak_seasons.iloc[0]['Year']\n",
        "        for year in stretch_of_peak_seasons['Year']:\n",
        "          if year - prev_year != 1 and year - prev_year != 0:\n",
        "            stretch_of_peak_seasons[\"Year\"] = stretch_of_peak_seasons[\"Year\"].astype(str)\n",
        "            years = ', '.join(stretch_of_peak_seasons[\"Year\"])\n",
        "            non_consecutive_years = 1\n",
        "            break\n",
        "          prev_year = year\n",
        "\n",
        "        if non_consecutive_years == 0:\n",
        "          years = f\"{stretch_of_peak_seasons.iloc[0]['Year']} - {stretch_of_peak_seasons.iloc[number_of_seasons_peak-1]['Year']}\"\n",
        "\n",
        "        cols = ['Years', 'Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP']\n",
        "        df_temp = pd.DataFrame([[years, stretch_of_peak_seasons.iloc[0]['Team'], valuestring_peak, valuestring_peak_2, valuestring_peak_3, mp]], columns=cols)\n",
        "        x_year_peak = pd.concat([x_year_peak, df_temp], ignore_index=False)\n",
        "        outfile = f\"{number_of_seasons_peak}_year_peak_relative_team_data.csv\"\n",
        "        x_year_peak.to_csv(outfile, index=False)\n",
        "      team_finished.append(stretch_of_peak_seasons.iloc[0]['Team'])\n",
        "\n",
        "\n",
        "#@title X Year Peaks Functions (Team)\n",
        "\n",
        "# returns if all values in a column are unique.\n",
        "\n",
        "\n",
        "# def x_yearpeak(source_df, valuestring, number_of_seasons_peak):\n",
        "# returns a dataframe containing x year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts x year stretches of 'valuestring' AND the listed years from each x year stretch + minutes played across the 2 seasons.\n",
        "def x_yearpeak_team_name(source_df, valuestring, valuestring_2, valuestring_3, number_of_seasons_peak):\n",
        "  x_year_peak = pd.DataFrame(columns = ['Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP'])\n",
        "\n",
        "  stretch_of_peak_seasons = source_df[(source_df['Team'] == source_df['Team'])]\n",
        "  stretch_of_peak_seasons = stretch_of_peak_seasons.reset_index(drop=True)\n",
        "\n",
        "  team_name = stretch_of_peak_seasons['Team'][0]\n",
        "  print(team_name)\n",
        "\n",
        "  mp = int(stretch_of_peak_seasons['MP'].sum())\n",
        "  stretch_of_peak_seasons[f'{valuestring}_Portion'] = stretch_of_peak_seasons[f'{valuestring}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "  stretch_of_peak_seasons[f'{valuestring_2}_Portion'] = stretch_of_peak_seasons[f'{valuestring_2}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "  stretch_of_peak_seasons[f'{valuestring_3}_Portion'] = stretch_of_peak_seasons[f'{valuestring_3}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "  valuestring_peak = stretch_of_peak_seasons[f'{valuestring}_Portion'].sum().round(2)\n",
        "  valuestring_peak_2 = stretch_of_peak_seasons[f'{valuestring_2}_Portion'].sum().round(2)\n",
        "  valuestring_peak_3 = stretch_of_peak_seasons[f'{valuestring_3}_Portion'].sum().round(2)\n",
        "\n",
        "\n",
        "  cols = ['Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP']\n",
        "  df_temp = pd.DataFrame([[stretch_of_peak_seasons.iloc[0]['Team'], valuestring_peak, valuestring_peak_2, valuestring_peak_3, mp]], columns=cols)\n",
        "  x_year_peak = pd.concat([x_year_peak, df_temp], ignore_index=False)\n",
        "  outfile = f\"{team_name}_year_peak_relative_team_data.csv\"\n",
        "  x_year_peak.to_csv(outfile, index=False)\n",
        "  team_finished.append(stretch_of_peak_seasons.iloc[0]['Team'])"
      ],
      "metadata": {
        "id": "gARDbX_YAWZm",
        "cellView": "form"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run 2-13 Year Team Data Peaks\n",
        "team_data = pd.read_csv('/content/Nash_Lebron.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "all_peaks = pd.DataFrame()\n",
        "\n",
        "years = 13\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'NetRtg+'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = year11.replace(',', '')\n",
        "    year11 = int(year11)\n",
        "\n",
        "    year12 = peak_years.split()[11]\n",
        "    year12 = year12.replace(',', '')\n",
        "    year12 = int(year12)\n",
        "\n",
        "    year13 = peak_years.split()[12]\n",
        "    year13 = int(year13)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    elif year12 - year11 >= 5:\n",
        "      continue\n",
        "    elif year13 - year12 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 12\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = year11.replace(',', '')\n",
        "    year11 = int(year11)\n",
        "\n",
        "    year12 = peak_years.split()[11]\n",
        "    year12 = int(year12)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    elif year12 - year11 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 11\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = int(year11)\n",
        "\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 10\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = int(year10)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 9\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = int(year9)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 8\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = int(year8)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 7\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = int(year7)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 6\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = int(year6)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 5\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = int(year5)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 4\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = int(year4)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 3\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = int(year3)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 2\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = int(year2)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "all_peaks.to_csv(f\"all_peaks_relative_team_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "eAVu5nK5Hs9h",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_data = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2024_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "all_peaks = pd.DataFrame()\n",
        "\n",
        "years = 22\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'NetRtg+'\n",
        "while years >= 2:\n",
        "  x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "  years = years - 1\n",
        "\n",
        "all_peaks = pd.DataFrame()\n",
        "year = 2\n",
        "while year < 23:\n",
        "  single_df = pd.read_csv(f'/content/{year}_year_peak_relative_team_data.csv', encoding='utf8')\n",
        "  all_peaks = pd.concat([all_peaks, single_df], ignore_index=True)\n",
        "  year = year + 1\n",
        "\n",
        "all_peaks = all_peaks[(all_peaks['MP'] >= 800)]\n",
        "all_peaks = all_peaks[(all_peaks['MP'] <= 15000)]\n",
        "all_peaks.to_csv('all_team_rating_peaks.csv', index=False)"
      ],
      "metadata": {
        "id": "QRcRCvAy3Vf-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_data = pd.read_csv('all_team_rating_peaks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "team_data = team_data[(team_data['MP'] >= 3000)]\n",
        "team_data = team_data[(team_data['MP'] <= 5000)]\n",
        "team_data.to_csv('5000_10000_MP.csv', index=False)"
      ],
      "metadata": {
        "id": "W_4DOHCwNRma"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2024_df.csv', index_col=False, encoding='utf8')"
      ],
      "metadata": {
        "id": "a4TlWI4aICCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print Series Ratings\n",
        "def printSeriesRtgs(dataframe, team, first_year, last_year, color_list):\n",
        "  dataframe = dataframe[(dataframe['Team'] == team)]\n",
        "  dataframe = dataframe[(dataframe['Year'] >= first_year)]\n",
        "  dataframe = dataframe[(dataframe['Year'] <= last_year)]\n",
        "\n",
        "  random.shuffle(plot_colors_set_list)\n",
        "  len_dif = 3 - len(color_list)\n",
        "  for i in range(0, len_dif):\n",
        "    color = plot_colors_set_list[i]\n",
        "    color_list.append(color)\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', \"OffRtg+\", \"DefRtg+\", \"NetRtg+\", f\"{team} MP\"])\n",
        "\n",
        "  min_ortg = 120\n",
        "  max_ortg = 0\n",
        "\n",
        "  min_drtg = 120\n",
        "  max_drtg = 0\n",
        "\n",
        "  min_netrtg = 120\n",
        "  max_netrtg = 0\n",
        "\n",
        "  for idx, row in dataframe.iterrows():\n",
        "\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      series_ortg = row[f\"OffRtg+\"]\n",
        "      series_drtg = row[f\"DefRtg+\"]\n",
        "      series_netrtg = row[f\"NetRtg+\"]\n",
        "\n",
        "      if series_ortg <= min_ortg:\n",
        "        min_ortg = series_ortg\n",
        "      if series_ortg >= max_ortg:\n",
        "        max_ortg = series_ortg\n",
        "\n",
        "      if series_drtg <= min_drtg:\n",
        "        min_drtg = series_drtg\n",
        "      if series_drtg >= max_drtg:\n",
        "        max_drtg = series_drtg\n",
        "\n",
        "      if series_netrtg <= min_netrtg:\n",
        "        min_netrtg = series_netrtg\n",
        "      if series_netrtg >= max_netrtg:\n",
        "        max_netrtg = series_netrtg\n",
        "\n",
        "      new_row = {'Series':series,  f\"OffRtg+\":series_ortg, f\"DefRtg+\":series_drtg, f\"NetRtg+\":series_netrtg, f\"{team} MP\":int(row['MP'])}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      final_season_df = pd.concat([final_season_df, new_df], ignore_index = True)\n",
        "      final_season_df.to_csv(f\"{team}_Series.csv\", index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1,\n",
        "                      right=0.9,\n",
        "                      top=0.9,\n",
        "                      wspace=0.4,\n",
        "                      hspace=0.4)\n",
        "\n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "\n",
        "  perc_file_name = f\"{team}_Series.csv\"\n",
        "\n",
        "  # off\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"NetRtg+\", \"DefRtg+\"])\n",
        "  columns_titles = ['Series', \"OffRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['OffRtg+'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[0]], ax=axis[0])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[0])\n",
        "  axis[0].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series OffRtg+ (opponent adjusted)\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel=\"OffRtg+ (opponent adjusted)\")\n",
        "  axis[0].set(ylim=(min_ortg-2, max_ortg+2))\n",
        "\n",
        "  # def\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"NetRtg+\", \"OffRtg+\"])\n",
        "  columns_titles = ['Series', \"DefRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['DefRtg+'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[1]], ax=axis[1])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[1])\n",
        "  axis[1].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series DefRtg+ (opponent adjusted)\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel=\"DefRtg+ (opponent adjusted)\")\n",
        "  axis[1].set(ylim=(min_drtg-2, max_drtg+2))\n",
        "\n",
        "  # net\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"OffRtg+\", \"DefRtg+\"])\n",
        "  columns_titles = ['Series', \"NetRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['NetRtg+'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[2]], ax=axis[2])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[2])\n",
        "  axis[2].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series NetRtg+ (opponent adjusted)\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel=\"NetRtg+ (opponent adjusted)\")\n",
        "  axis[2].set(ylim=(min_netrtg-2, max_netrtg+2))\n",
        "\n",
        "\n",
        "  fig.savefig(f'/content/Graph_{team}_Series', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def printTwoSeriesRtgs(dataframe, team1, team2, first_year, last_year, c1, c2, label_size):\n",
        "  dataframe = dataframe[(dataframe['Team'] == team1) | (dataframe['Team'] == team2)]\n",
        "  dataframe = dataframe[(dataframe['Year'] >= first_year)]\n",
        "  dataframe = dataframe[(dataframe['Year'] <= last_year)]\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Year', 'Team', 'Series', \"OffRtg+\", \"DefRtg+\", \"NetRtg+\", \"MP\"])\n",
        "\n",
        "  min_ortg = 120\n",
        "  max_ortg = 0\n",
        "\n",
        "  min_drtg = 120\n",
        "  max_drtg = 0\n",
        "\n",
        "  min_netrtg = 120\n",
        "  max_netrtg = 0\n",
        "\n",
        "  for idx, row in dataframe.iterrows():\n",
        "\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      series_ortg = row[f\"OffRtg+\"]\n",
        "      series_drtg = row[f\"DefRtg+\"]\n",
        "      series_netrtg = row[f\"NetRtg+\"]\n",
        "\n",
        "      if series_ortg <= min_ortg:\n",
        "        min_ortg = series_ortg\n",
        "      if series_ortg >= max_ortg:\n",
        "        max_ortg = series_ortg\n",
        "\n",
        "      if series_drtg <= min_drtg:\n",
        "        min_drtg = series_drtg\n",
        "      if series_drtg >= max_drtg:\n",
        "        max_drtg = series_drtg\n",
        "\n",
        "      if series_netrtg <= min_netrtg:\n",
        "        min_netrtg = series_netrtg\n",
        "      if series_netrtg >= max_netrtg:\n",
        "        max_netrtg = series_netrtg\n",
        "\n",
        "      new_row = {'Year':row['Year'], 'Team':row['Team'], 'Series':series,  f\"OffRtg+\":series_ortg, f\"DefRtg+\":series_drtg, f\"NetRtg+\":series_netrtg, \"MP\":int(row['MP'])}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      final_season_df = pd.concat([final_season_df, new_df], ignore_index = True)\n",
        "      final_season_df.to_csv(f\"{team1}_{team2}_Series.csv\", index=False)\n",
        "\n",
        "  perc_file_name = f\"{team1}_{team2}_Series.csv\"\n",
        "\n",
        "  final_season_df['index'] = final_season_df.index\n",
        "  final_season_df = final_season_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "\n",
        "  series_done = []\n",
        "\n",
        "  final_series_df = pd.DataFrame(columns = ['Series', f\"{team1} OffRtg+\", f\"{team1} DefRtg+\", f\"{team1} NetRtg+\", f\"{team2} OffRtg+\", f\"{team2} DefRtg+\", f\"{team2} NetRtg+\"])\n",
        "\n",
        "  for idx, row in final_season_df.iterrows():\n",
        "\n",
        "    display_series_opponent = 0\n",
        "\n",
        "    selected_series = str(row['Team']) + str(row['Series'])\n",
        "    if selected_series not in series_done:\n",
        "      if row['Team'] == team1:\n",
        "        offrtg_1 = row['OffRtg+']\n",
        "        defrtg_1 = row['DefRtg+']\n",
        "        netrtg_1 = row['NetRtg+']\n",
        "        offrtg_2 = 0\n",
        "        defrtg_2 = 0\n",
        "        netrtg_2 = 0\n",
        "        this_series = str(row['Team']) + str(row['Series'])\n",
        "        series_done.append(this_series)\n",
        "      else:\n",
        "        offrtg_2 = row['OffRtg+']\n",
        "        defrtg_2 = row['DefRtg+']\n",
        "        netrtg_2 = row['NetRtg+']\n",
        "        offrtg_1 = 0\n",
        "        defrtg_1 = 0\n",
        "        netrtg_1 = 0\n",
        "        this_series = str(row['Team']) + str(row['Series'])\n",
        "        series_done.append(this_series)\n",
        "\n",
        "      new_row = {'Series':row['Series'],  f\"{team1} OffRtg+\":offrtg_1, f\"{team1} DefRtg+\":defrtg_1, f\"{team1} NetRtg+\":netrtg_1, f\"{team2} OffRtg+\":offrtg_2, f\"{team2} DefRtg+\":defrtg_2, f\"{team2} NetRtg+\":netrtg_2}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      final_series_df = pd.concat([final_series_df, new_df], ignore_index = True)\n",
        "      outfile = f\"{team1}_{team2}_Series_Melt.csv\"\n",
        "      final_series_df.to_csv(outfile, index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1,\n",
        "                      right=0.9,\n",
        "                      top=0.9,\n",
        "                      wspace=0.4,\n",
        "                      hspace=0.4)\n",
        "\n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=label_size)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=label_size)\n",
        "  axis[2].tick_params(axis='x', which='major', labelsize=label_size)\n",
        "\n",
        "  perc_file_name = f\"{team1}_{team2}_Series_Melt.csv\"\n",
        "\n",
        "  # off\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team1} DefRtg+\",f\"{team2} DefRtg+\", f\"{team1} NetRtg+\",f\"{team2} NetRtg+\"])\n",
        "  columns_titles = ['Series', f\"{team1} OffRtg+\", f\"{team2} OffRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{team1} OffRtg+', f'{team2} OffRtg+'], value_name=\"rtg\", var_name ='Team Key')\n",
        "  graph_data = graph_data[graph_data['rtg'] != 0]\n",
        "  graph_data = graph_data.sort_values(\"Series\", ascending=True)\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Team Key\", palette=[c1, c2], ax=axis[0])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[0])\n",
        "  axis[0].margins(x=0)\n",
        "\n",
        "  titlestring = \"Playoff Series OffRtg+ (opponent adjusted)\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel=\"OffRtg+ (opponent adjusted)\")\n",
        "  axis[0].set(ylim=(min_ortg-2, max_ortg+2))\n",
        "\n",
        "  # def\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team1} OffRtg+\",f\"{team2} OffRtg+\", f\"{team1} NetRtg+\",f\"{team2} NetRtg+\"])\n",
        "  columns_titles = ['Series', f\"{team1} DefRtg+\", f\"{team2} DefRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{team1} DefRtg+', f'{team2} DefRtg+'], value_name=\"rtg\", var_name ='Team Key')\n",
        "  graph_data = graph_data[graph_data['rtg'] != 0]\n",
        "  graph_data = graph_data.sort_values(\"Series\", ascending=True)\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Team Key\", palette=[c1, c2], ax=axis[1])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[1])\n",
        "  axis[1].margins(x=0)\n",
        "\n",
        "  titlestring = \"Playoff Series DefRtg+ (opponent adjusted)\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel=\"DefRtg+ (opponent adjusted)\")\n",
        "  axis[1].set(ylim=(min_drtg-2, max_drtg+2))\n",
        "\n",
        "  # net\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=[f\"{team1} OffRtg+\",f\"{team2} OffRtg+\", f\"{team1} DefRtg+\",f\"{team2} DefRtg+\"])\n",
        "  columns_titles = ['Series', f\"{team1} NetRtg+\", f\"{team2} NetRtg+\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{team1} NetRtg+', f'{team2} NetRtg+'], value_name=\"rtg\", var_name ='Team Key')\n",
        "  graph_data = graph_data[graph_data['rtg'] != 0]\n",
        "  graph_data = graph_data.sort_values(\"Series\", ascending=True)\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Team Key\", palette=[c1, c2], ax=axis[2])\n",
        "\n",
        "  sns.lineplot(data = graph_data, x='Series', y=100, markers=True, alpha=1, color='k', linewidth = 4, ax=axis[2])\n",
        "  axis[2].margins(x=0)\n",
        "\n",
        "  titlestring = \"Playoff Series NetRtg+ (opponent adjusted)\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel=\"NetRtg+ (opponent adjusted)\")\n",
        "  axis[2].set(ylim=(min_netrtg-2, max_netrtg+2))\n",
        "\n",
        "\n",
        "  fig.savefig(f'/content/Graph_{team1}_{team2}_Series_Rtgs', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Cf0fQ4WGHyVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print Series Ratings (2)\n",
        "def printSeriesRtgs(dataframe, team, first_year, last_year, color_list):\n",
        "  dataframe = dataframe[(dataframe['Team'] == team)]\n",
        "  dataframe = dataframe[(dataframe['Year'] >= first_year)]\n",
        "  dataframe = dataframe[(dataframe['Year'] <= last_year)]\n",
        "\n",
        "  random.shuffle(plot_colors_set_list)\n",
        "  len_dif = 3 - len(color_list)\n",
        "  for i in range(0, len_dif):\n",
        "    color = plot_colors_set_list[i]\n",
        "    color_list.append(color)\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', \"OffRtg+ Percentile\", \"DefRtg+ Percentile\", \"NetRtg+ Percentile\", f\"{team} MP\"])\n",
        "\n",
        "  for idx, row in dataframe.iterrows():\n",
        "\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      series_ortg = row[f\"OffRtg+\"]\n",
        "      series_drtg = row[f\"DefRtg+\"]\n",
        "      series_netrtg = row[f\"NetRtg+\"]\n",
        "\n",
        "      offrtg_percentile = stats.percentileofscore(dataframe['OffRtg+'], series_ortg)\n",
        "      defrtg_percentile = stats.percentileofscore(dataframe['DefRtg+'], series_drtg)\n",
        "      netrtg_percentile = stats.percentileofscore(dataframe['NetRtg+'], series_netrtg)\n",
        "\n",
        "\n",
        "\n",
        "      new_row = {'Series':series, 'OffRtg+ Percentile': offrtg_percentile, 'DefRtg+ Percentile': defrtg_percentile, 'NetRtg+ Percentile': netrtg_percentile, f\"{team} MP\":int(row['MP'])}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      final_season_df = pd.concat([final_season_df, new_df], ignore_index = True)\n",
        "      final_season_df.to_csv(f\"{team}_Series.csv\", index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1,\n",
        "                      right=0.9,\n",
        "                      top=0.9,\n",
        "                      wspace=0.4,\n",
        "                      hspace=0.4)\n",
        "\n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "\n",
        "  perc_file_name = f\"{team}_Series.csv\"\n",
        "\n",
        "  # off\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"NetRtg+ Percentile\", \"DefRtg+ Percentile\"])\n",
        "  columns_titles = ['Series', \"OffRtg+ Percentile\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['OffRtg+ Percentile'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[0]], ax=axis[0])\n",
        "\n",
        "  axis[0].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series OffRtg+ (opponent adjusted)\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel=\"OffRtg+ Percentile (1957 - 2023)\")\n",
        "\n",
        "  # def\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"NetRtg+ Percentile\", \"OffRtg+ Percentile\"])\n",
        "  columns_titles = ['Series', \"DefRtg+ Percentile\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['DefRtg+ Percentile'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[1]], ax=axis[1])\n",
        "\n",
        "  axis[1].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series DefRtg+ (opponent adjusted)\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel=\"DefRtg+ Percentile (1957 - 2023)\")\n",
        "\n",
        "  txt=\"'OffRtg+'   - Teams' playoff OffRtg / Opponents' regular season DefRtg\\n'DefRtg+'  - Opponents' regular season OffRtg / Teams' playoff DefRtg\\n1957-1973 ORB & TOV data estimated; 1974-1983 ORB & TOV data estimated as necessary\"\n",
        "  plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=24)\n",
        "\n",
        "  # net\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{team} MP\", \"OffRtg+ Percentile\", \"DefRtg+ Percentile\"])\n",
        "  columns_titles = ['Series', \"NetRtg+ Percentile\"]\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['NetRtg+ Percentile'], value_name=\"rtg\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y=\"rtg\", hue=\"Player Key\", palette=[color_list[2]], ax=axis[2])\n",
        "\n",
        "  axis[2].margins(x=0)\n",
        "\n",
        "  titlestring = f\"{team} Playoff Series NetRtg+ (opponent adjusted)\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel=\"NetRtg+ Percentile (1957 - 2023)\")\n",
        "\n",
        "\n",
        "  fig.savefig(f'/content/Graph_{team}_Series', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "SmhVpvhXZd2V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print Series Ratings vs Opp & non Opponent\n",
        "def printSeriesRtgsVsOpp(dataframe, team, first_year, last_year, opponent, what_rtg):\n",
        "  dataframe = dataframe[(dataframe['Team'] == team)]\n",
        "  dataframe = dataframe[(dataframe['Year'] >= first_year)]\n",
        "  dataframe = dataframe[(dataframe['Year'] <= last_year)]\n",
        "\n",
        "  vs_opp_df = pd.DataFrame(columns = ['Series', \"OffRtg+\", \"DefRtg+\", \"NetRtg+\", \"MP\"])\n",
        "  vs_non_opp_df = pd.DataFrame(columns = ['Series', \"OffRtg+\", \"DefRtg+\", \"NetRtg+\", \"MP\"])\n",
        "\n",
        "  min_ortg = 120\n",
        "  max_ortg = 0\n",
        "\n",
        "  min_drtg = 120\n",
        "  max_drtg = 0\n",
        "\n",
        "  min_netrtg = 120\n",
        "  max_netrtg = 0\n",
        "\n",
        "  for idx, row in dataframe.iterrows():\n",
        "\n",
        "    if row['Opp'] == opponent:\n",
        "\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      series_ortg = row[f\"OffRtg+\"]\n",
        "      series_drtg = row[f\"DefRtg+\"]\n",
        "      series_netrtg = row[f\"NetRtg+\"]\n",
        "\n",
        "      new_row = {'Series':series,  f\"OffRtg+\":series_ortg, f\"DefRtg+\":series_drtg, f\"NetRtg+\":series_netrtg, \"MP\":int(row['MP'])}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      vs_opp_df = pd.concat([vs_opp_df, new_df], ignore_index = True)\n",
        "    else:\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      series_ortg = row[f\"OffRtg+\"]\n",
        "      series_drtg = row[f\"DefRtg+\"]\n",
        "      series_netrtg = row[f\"NetRtg+\"]\n",
        "\n",
        "      new_row = {'Series':series,  f\"OffRtg+\":series_ortg, f\"DefRtg+\":series_drtg, f\"NetRtg+\":series_netrtg, \"MP\":int(row['MP'])}\n",
        "      new_df = pd.DataFrame(new_row, index=[0])\n",
        "      vs_non_opp_df = pd.concat([vs_non_opp_df, new_df], ignore_index = True)\n",
        "  print(vs_non_opp_df)\n",
        "  print(vs_opp_df)\n",
        "\n",
        "  opp_mp = int(vs_opp_df['MP'].sum())\n",
        "  non_opp_mp = int(vs_non_opp_df['MP'].sum())\n",
        "\n",
        "  vs_non_opp_df[f'{what_rtg}_Portion'] = vs_non_opp_df[f'{what_rtg}'] * (vs_non_opp_df['MP'] / non_opp_mp)\n",
        "  vs_opp_df[f'{what_rtg}_Portion'] = vs_opp_df[f'{what_rtg}'] * (vs_opp_df['MP'] / opp_mp)\n",
        "\n",
        "  non_opp_rtg = vs_non_opp_df[f'{what_rtg}_Portion'].sum()\n",
        "  opp_rtg = vs_opp_df[f'{what_rtg}_Portion'].sum()\n",
        "\n",
        "  opp_rtg = round(opp_rtg, 2)\n",
        "  non_opp_rtg = round(non_opp_rtg, 2)\n",
        "\n",
        "  print(f\"\\n{what_rtg} vs {opponent}: {opp_rtg}\\nMP: {opp_mp}\")\n",
        "  print(f\"\\n{what_rtg} vs non-{opponent} opponents: {non_opp_rtg}\\nMP: {non_opp_mp}\")"
      ],
      "metadata": {
        "id": "xrfPrygB-E_K",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printSeriesRtgsVsOpp(df, \"SAS\", 1977, 1988, \"LAL\", \"OffRtg+\")"
      ],
      "metadata": {
        "id": "iRFiPfDh_ua6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2023_df.csv', index_col=False, encoding='utf8')\n",
        "printSeriesRtgs(df, \"DET\", 1990, 2004, [\"#F58426\", \"#1D428A\", \"#EF426F\"])"
      ],
      "metadata": {
        "id": "fzzKXzeEJve2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printTwoSeriesRtgs(df, \"SAS\", \"LAL\", 1999, 2016, \"m\", \"g\", 8)"
      ],
      "metadata": {
        "id": "ylzQjfXTgsZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Scrape ABA Playoff Teams' OffRtg+ and rDefRtg+\n",
        "def scrape_playoff_rOffRtg_rDefRtg(origal_team_df):\n",
        "\n",
        "\n",
        "  teams_defense = pd.read_csv('/content/aba_Team_DefRtg_Allowed_74-76_df.csv', index_col=False, encoding='utf8')\n",
        "  teams_offense = pd.read_csv('/content/aba_Team_OffRtg_74-76_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  fiftytwo_seventythree_off_def_rtgs = pd.read_csv('/content/aba_Team_Estimated_Pace_68-73_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  missing_mp = pd.read_csv('/content/missing_mp_aba.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "  team_df = pd.DataFrame(columns = ['Year', 'Team', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "  total_series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "\n",
        "  for idx, row in origal_team_df.iterrows():\n",
        "\n",
        "    use_different_pace_formula = 0\n",
        "    dont_estimate_pace = 0\n",
        "\n",
        "    original_team = str(row['Team'])\n",
        "    series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "\n",
        "    team_url = \"https://www.basketball-reference.com/teams/\" + row['Team'] + \"/\" + str(row['Year']) + \".html\"\n",
        "\n",
        "    html = urlopen(team_url)\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'info'}):\n",
        "      second_div = first_div.find('div', attrs={'id': 'meta'})\n",
        "      second_div = str(second_div)\n",
        "      ref_urls = re.findall(r'/\\w+\\/\\d+[0-9abcdefghijklmnopqrstuvwxyz-]+', second_div)\n",
        "      urls = []\n",
        "      for ref_url in ref_urls:\n",
        "        if \"eastern\" in ref_url or \"western\" in ref_url or \"finals\" in ref_url:\n",
        "          ref_url = \"https://www.basketball-reference.com\" + ref_url + \".html\"\n",
        "          urls.append(ref_url)\n",
        "    for series_url in urls:\n",
        "\n",
        "      time.sleep(6)\n",
        "      html = urlopen(series_url)\n",
        "      soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_four_factors'})\n",
        "\n",
        "      second_div = str(second_div)\n",
        "\n",
        "      teams = re.findall(r'/\\w+\\/\\d+', second_div)\n",
        "      count = 0\n",
        "      for team in teams:\n",
        "        if count == 0:\n",
        "          if str(row['Team']) in team:\n",
        "            team_in = 0\n",
        "          else:\n",
        "            team_in = 1\n",
        "            other_team = team\n",
        "        else:\n",
        "          if str(row['Team']) not in team:\n",
        "            other_team = team\n",
        "        count = count + 1\n",
        "      year = row['Year']\n",
        "      other_team = other_team.replace(f'{year}', '')\n",
        "      other_team = other_team.replace(f'/', '')\n",
        "\n",
        "      rtgs_untrimmed = re.findall(r'off_rtg\" >\\d+.\\d+', second_div)\n",
        "\n",
        "      # no OffRtg's. Need to estimate them given boxscore.\n",
        "      if not rtgs_untrimmed:\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "\n",
        "        # most likely have TOV data\n",
        "        if year >= 1974:\n",
        "\n",
        "          # team data to estimate pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            mp_untrimmed = mp_untrimmed[-1]\n",
        "            mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            fta = int(fta)\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            try:\n",
        "              tov_untrimmed = tov_untrimmed[-1]\n",
        "              tov = tov_untrimmed.replace(f'data-stat=\"tov\" >', '')\n",
        "              tov = int(tov)\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              continue\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            OffRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            original_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "          else:\n",
        "            original_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          use_different_pace_formula = 0\n",
        "          dont_estimate_pace = 0\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            tov_untrimmed = tov_untrimmed[-1]\n",
        "            tov = tov_untrimmed.replace(f'data-stat=\"tov\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                  TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            fga = int(series_data['FGA'])\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            DefRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "          else:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "\n",
        "          other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "          other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_offrtg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "        # will not have TOV data\n",
        "        else:\n",
        "          if year >= 1971:\n",
        "            TOV_percent = 0.158\n",
        "          else:\n",
        "            TOV_percent = 0.161\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            try:\n",
        "              mp_untrimmed = mp_untrimmed[-1]\n",
        "              mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            except:\n",
        "              mp = missing_mp[(missing_mp['Team'] == original_team) & (missing_mp['Year'] == year)]\n",
        "              mp = mp['MP']\n",
        "              mp = int(mp)\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              continue\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              continue\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          possessions = (total_fga + (0.4 * total_fta) - ORB_percent * (total_fga - total_fg) + (-TOV_percent * (total_fga + 0.44 * total_fta) / (TOV_percent - 1))) / 2\n",
        "          DefRtg = pts / possessions * 100\n",
        "          OffRtg = original_pts / possessions * 100\n",
        "\n",
        "          other_team_defrtg_ortg = fiftytwo_seventythree_off_def_rtgs[(fiftytwo_seventythree_off_def_rtgs['Year'] == year) & (fiftytwo_seventythree_off_def_rtgs['Team'] == other_team)]\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg_ortg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_defrtg_ortg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "      # have OffRtg's, can use them\n",
        "      else:\n",
        "        count = 0\n",
        "        for rtg in rtgs_untrimmed:\n",
        "          rtg = rtg.replace('off_rtg\" >', '')\n",
        "          if count == 0 and team_in == 0:\n",
        "            off_rtg = rtg\n",
        "          elif count == 1 and team_in == 0:\n",
        "            def_rtg = rtg\n",
        "          elif count == 0 and team_in == 1:\n",
        "            def_rtg = rtg\n",
        "          elif count == 1 and team_in == 1:\n",
        "            off_rtg = rtg\n",
        "          count = count + 1\n",
        "\n",
        "        other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "\n",
        "        other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "        r_OffRtg = float(off_rtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "        r_DefRtg = float(other_team_offrtg['OffRtg']) / float(def_rtg)* 100\n",
        "\n",
        "        r_OffRtg = round(r_OffRtg, 1)\n",
        "        r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "\n",
        "        first_div = soup.find('div', attrs={'id': 'content'})\n",
        "        second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "        first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "        if first_table == None:\n",
        "          second_div_str = str(second_div)\n",
        "          mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "          mp_untrimmed = mp_untrimmed[-1]\n",
        "          mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "          mp = int(mp) // 5\n",
        "        else:\n",
        "          header = first_table.find('thead')\n",
        "          foot = first_table.find('tfoot')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "          rows = foot.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "          #create df\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          pts_count = 0\n",
        "          mp_count = 0\n",
        "          cols = []\n",
        "          for column in series_data.columns:\n",
        "            if column == 'MP':\n",
        "              if mp_count == 1:\n",
        "                cols.append(f'MPG')\n",
        "              else:\n",
        "                cols.append(f'MP')\n",
        "              mp_count+=1\n",
        "              continue\n",
        "            if column == 'PTS':\n",
        "              if pts_count == 1:\n",
        "                cols.append(f'PTS/G')\n",
        "              else:\n",
        "                cols.append(f'PTS')\n",
        "              pts_count+=1\n",
        "              continue\n",
        "            cols.append(column)\n",
        "          series_data.columns = cols\n",
        "\n",
        "          mp = int(series_data['MP'])\n",
        "          mp = int(mp // 5)\n",
        "\n",
        "      new_row = pd.DataFrame(np.array([[year, original_team, other_team, r_OffRtg, r_DefRtg, mp]]), columns=['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "      series_df = pd.concat([series_df, new_row], ignore_index=True)\n",
        "      total_series_df = pd.concat([total_series_df, new_row], ignore_index=True)\n",
        "      series_df['MP'] = series_df['MP'].astype(int)\n",
        "      total_series_df['MP'] = total_series_df['MP'].astype(int)\n",
        "\n",
        "    mp = int(series_df['MP'].sum())\n",
        "    print(series_df)\n",
        "\n",
        "    for idx, row in series_df.iterrows():\n",
        "\n",
        "      series_df.loc[idx, 'OffRtg+_Portion'] = float(series_df.loc[idx, 'OffRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "      series_df.loc[idx, 'DefRtg+_Portion'] = float(series_df.loc[idx, 'DefRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "    try:\n",
        "      rOffRtg_avg = series_df[f'OffRtg+_Portion'].sum().round(1)\n",
        "      rDefRtg_avg = series_df[f'DefRtg+_Portion'].sum().round(1)\n",
        "\n",
        "      new_row = pd.DataFrame(np.array([[year, original_team, rOffRtg_avg, rDefRtg_avg, mp]]), columns=['Year', 'Team', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "      team_df = pd.concat([team_df, new_row], ignore_index=True)\n",
        "\n",
        "      total_series_df.to_csv('aba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1968_1976_df.csv', index=False)\n",
        "      team_df.to_csv('aba_Playoff_rOffRtg_rDefRtg_1968_1976_df.csv', index=False)\n",
        "      print(team_df)\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "-ArcEcjk49dL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}